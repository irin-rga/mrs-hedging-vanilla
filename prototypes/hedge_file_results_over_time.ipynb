{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "from pandas import DataFrame as df\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from os import path\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "\n",
    "from mthly_hedge_file import HedgeFile\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fldr = r'C:\\Users\\S0053071\\Repos\\Orion_Process_Backup\\HdgRpts_Results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_removed_items(orig_df, true_df):\n",
    "    \"\"\"\n",
    "    Returns a dataframe containing only records that have been removed\n",
    "    \"\"\"\n",
    "    join_cols = ['HedgeDate', 'CompID', 'Indicator', 'Bbg_Idx', 'Fund_Name', 'Opt_Type', 'Strike', 'Cap/Rate', 'Budget']\n",
    "    rename_cols = ['PolicyCount', 'Base_Liab_Ntnl', 'Notional']\n",
    "    final_cols = ['Attrib_Type', 'HedgeDate', 'CompID', 'Indicator', 'Bbg_Idx', 'Fund_Name', 'Opt_Type', 'Strike', 'Cap/Rate', 'Budget', 'PolicyCount', 'Base_Liab_Ntnl', 'Notional']\n",
    "\n",
    "    rename_cols_prev = { col: col + '_Prev' for col in rename_cols}\n",
    "    rename_cols_curr = { col: col + '_Curr' for col in rename_cols}\n",
    "\n",
    "    prev_df = orig_df.rename(columns=rename_cols_prev, errors=\"raise\")\n",
    "    curr_df = true_df.rename(columns=rename_cols_curr, errors=\"raise\") # .drop(columns=['Record_Type', 'Co_Code', 'Val_Date', 'Best_Val_Ind'])\n",
    "\n",
    "    # join_cols = ['Fund_ID', 'Eff_Date', 'Price_Eff_Dt', 'Cap_Rate', 'Cap_Plus_Accel', 'Part_Rate', 'Price_Reset', 'Best_Val_Ind']\n",
    "    \n",
    "    maturing_df = pd.merge(prev_df, curr_df, how='outer', on=join_cols, indicator=True)\n",
    "\n",
    "    # maturing_df = pd.DataFrame(self.prev_results[maturing_df['_merge'] == 'left_only'])\n",
    "    maturing_df = pd.DataFrame(maturing_df[maturing_df['_merge'] == 'left_only'])\n",
    "    \n",
    "    maturing_df['PolicyCount'] = -maturing_df['PolicyCount_Prev']\n",
    "    maturing_df['Base_Liab_Ntnl'] = -maturing_df['Base_Liab_Ntnl_Prev']\n",
    "    maturing_df['Notional'] = -maturing_df['Notional_Prev']\n",
    "    maturing_df['Attrib_Type'] = 'Removed'\n",
    "    maturing_df = maturing_df[final_cols]\n",
    "\n",
    "    return maturing_df\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_items(orig_df, true_df):\n",
    "    \"\"\"\n",
    "    Returns a dataframe containing only records that are new\n",
    "    \"\"\"\n",
    "    join_cols = ['HedgeDate', 'CompID', 'Indicator', 'Bbg_Idx', 'Fund_Name', 'Opt_Type', 'Strike', 'Cap/Rate', 'Budget']\n",
    "    rename_cols = ['PolicyCount', 'Base_Liab_Ntnl', 'Notional']\n",
    "    final_cols = ['Attrib_Type', 'HedgeDate', 'CompID', 'Indicator', 'Bbg_Idx', 'Fund_Name', 'Opt_Type', 'Strike', 'Cap/Rate', 'Budget', 'PolicyCount', 'Base_Liab_Ntnl', 'Notional']\n",
    "\n",
    "    rename_cols_prev = { col: col + '_Prev' for col in rename_cols}\n",
    "    rename_cols_curr = { col: col + '_Curr' for col in rename_cols}\n",
    "\n",
    "    prev_df = orig_df.rename(columns=rename_cols_prev, errors=\"raise\")\n",
    "    curr_df = true_df.rename(columns=rename_cols_curr, errors=\"raise\") # .drop(columns=['Record_Type', 'Co_Code', 'Val_Date', 'Best_Val_Ind'])\n",
    "\n",
    "    new_df = pd.merge(prev_df, curr_df, how='outer', on=join_cols, indicator=True)\n",
    "    new_df = pd.DataFrame(new_df[new_df['_merge'] == 'right_only'])\n",
    "    \n",
    "    new_df['PolicyCount'] = new_df['PolicyCount_Curr']\n",
    "    new_df['Base_Liab_Ntnl'] = new_df['Base_Liab_Ntnl_Curr']\n",
    "    new_df['Notional'] = new_df['Notional_Curr']\n",
    "    new_df['Attrib_Type'] = 'Added'\n",
    "\n",
    "    new_df = new_df[final_cols]\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_changed_items(orig_df, true_df):\n",
    "    \"\"\"\n",
    "    Returns a dataframe of changed items that exist both on the orig and true-up files\n",
    "    \"\"\"\n",
    "    join_cols = ['HedgeDate', 'CompID', 'Indicator', 'Bbg_Idx', 'Fund_Name', 'Opt_Type', 'Strike', 'Cap/Rate', 'Budget']\n",
    "    rename_cols = ['PolicyCount', 'Base_Liab_Ntnl', 'Notional']\n",
    "    final_cols = ['Attrib_Type', 'HedgeDate', 'CompID', 'Indicator', 'Bbg_Idx', 'Fund_Name', 'Opt_Type', 'Strike', 'Cap/Rate', 'Budget', 'PolicyCount', 'Base_Liab_Ntnl', 'Notional']\n",
    "\n",
    "    rename_cols_prev = { col: col + '_Prev' for col in rename_cols}\n",
    "    rename_cols_curr = { col: col + '_Curr' for col in rename_cols}\n",
    "\n",
    "    prev_df = orig_df.rename(columns=rename_cols_prev, errors=\"raise\")\n",
    "    curr_df = true_df.rename(columns=rename_cols_curr, errors=\"raise\") # .drop(columns=['Record_Type', 'Co_Code', 'Val_Date', 'Best_Val_Ind'])\n",
    "\n",
    "    chg_df = pd.merge(prev_df, curr_df, how='inner', on=join_cols)\n",
    "    \n",
    "    chg_df['PolicyCount'] = chg_df['PolicyCount_Curr'] - chg_df['PolicyCount_Prev']\n",
    "    chg_df['Base_Liab_Ntnl'] = chg_df['Base_Liab_Ntnl_Curr'] - chg_df['Base_Liab_Ntnl_Prev']\n",
    "    chg_df['Notional'] = chg_df['Notional_Curr'] - chg_df['Notional_Prev']\n",
    "    chg_df['Attrib_Type'] = 'Changed'\n",
    "\n",
    "    chg_df = chg_df[final_cols]\n",
    "\n",
    "    chg_df = chg_df[chg_df['Base_Liab_Ntnl']!=0]\n",
    "        \n",
    "    return chg_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_attrib_df(orig_df, true_df):\n",
    "        \"\"\"\n",
    "        Creates a dataframe from removed items, new items and change in existing items\n",
    "        \"\"\"        \n",
    "        attrib_df = pd.concat([get_removed_items(orig_df, true_df), get_new_items(orig_df, true_df), get_changed_items(orig_df, true_df)]).reset_index(drop=True)\n",
    "        \n",
    "        return attrib_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_subdir_hdgfiles(target_dir, directories_to_process=None):\n",
    "    \"\"\"\n",
    "    Iterates over the subdirectories of a given directory and prints their paths.\n",
    "\n",
    "    Args:\n",
    "        target_dir: The path to the directory to iterate over.\n",
    "    \"\"\"\n",
    "    \n",
    "    final_cols = ['HedgeFile_Dt', 'Attrib_Type', 'HedgeDate', 'CompID', 'Indicator', 'Bbg_Idx', 'Fund_Name', 'Opt_Type', 'Strike', 'Cap/Rate', 'Budget', 'PolicyCount', 'Base_Liab_Ntnl', 'Notional']\n",
    "    df_cols = ['HedgeDate',\t'CompID', 'Indicator', 'Bbg_Idx', 'Fund_Name', 'Opt_Type', 'Strike', 'Cap/Rate', 'Budget', 'PolicyCount', 'Base_Liab_Ntnl', 'Notional']\n",
    "\n",
    "\n",
    "    orig_file = 'iul_liab_summary.csv'\n",
    "    true_file = 'iul_liab_summary_TRUE_UP.csv'\n",
    "    results_df = None\n",
    "\n",
    "    target_dir = Path(target_dir)\n",
    "\n",
    "    if directories_to_process is None:\n",
    "        # Set directories to all the valid directories\n",
    "        # directories_to_process = [x[1] for x  in os.walk(target_dir)]\n",
    "        # directories_to_process = directories_to_process[0]\n",
    "        directories_to_process = [f.name for f in target_dir.iterdir() if f.is_dir()]\n",
    "    \n",
    "    for dirpath, dirnames, filenames in os.walk(target_dir):\n",
    "        \n",
    "        for dirname in dirnames:\n",
    "\n",
    "            if dirname in directories_to_process:\n",
    "\n",
    "                # found_orig, found_true = False\n",
    "                inforce_dt = hedge_dt = None\n",
    "\n",
    "                subdir_path = os.path.join(dirpath, dirname)\n",
    "\n",
    "                if os.path.isdir(subdir_path):\n",
    "\n",
    "                    orig_path = os.path.join(subdir_path, orig_file)\n",
    "                    true_path = os.path.join(subdir_path, true_file)\n",
    "\n",
    "                    if os.path.exists(orig_path):\n",
    "                        # found_orig = True\n",
    "                        orig_df = pd.read_csv(orig_path)\n",
    "                        orig_df = orig_df[df_cols]\n",
    "\n",
    "                        orig_df['HedgeDate'] = pd.to_datetime(orig_df['HedgeDate']).dt.date\n",
    "                        hedge_dt = orig_df['HedgeDate'].max()\n",
    "                        \n",
    "                        # file_name = os.path.basename(orig_path)\n",
    "                        # hdg_mth = int(file_name[:2])\n",
    "                        # hdg_yr = int(file_name[3:7])\n",
    "                        # inforce_dt = date(hdg_yr, hdg_mth, 1)\n",
    "                        \n",
    "\n",
    "                    if os.path.exists(true_path):\n",
    "                        # found_true = True\n",
    "                        true_df = pd.read_csv(true_path)\n",
    "                        true_df = true_df[df_cols]\n",
    "                        true_df['HedgeDate'] = pd.to_datetime(true_df['HedgeDate']).dt.date\n",
    "\n",
    "                    # Create diffs summary if both files are found\n",
    "                    # if found_orig and found_true:\n",
    "                    # NOTE: Copied orig to true-up or vice versa in results dir to make sure both existed in every case (results will be 0 in this case, since no diffs will be found)\n",
    "                    chgs_df = create_attrib_df(orig_df, true_df)\n",
    "\n",
    "                    # orig_df['Attrib_Type'] = 'New' if orig_df['HedgeDate']==hedge_dt else 'Added'\n",
    "                    orig_df['Attrib_Type'] = orig_df.apply(lambda row: 'New' if row['HedgeDate']==hedge_dt else 'Added', axis=1)\n",
    "\n",
    "                    orig_df['HedgeFile_Dt'] = hedge_dt\n",
    "                    chgs_df['HedgeFile_Dt'] = hedge_dt\n",
    "\n",
    "                    orig_df = orig_df[final_cols]\n",
    "                    chgs_df = chgs_df[final_cols]\n",
    "\n",
    "                    if results_df is not None:\n",
    "                        results_df = pd.concat([results_df, orig_df, chgs_df]).reset_index(drop=True)\n",
    "                    else:\n",
    "                        results_df = pd.concat([orig_df, chgs_df]).reset_index(drop=True)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dirs = ['202405']\n",
    "test_df = process_subdir_hdgfiles(results_fldr, directories_to_process=test_dirs)\n",
    "test_df.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S0053071\\Repos\\Orion_Process_Backup\\HdgRpts_Results\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['202307',\n",
       " '202308',\n",
       " '202309',\n",
       " '202310',\n",
       " '202311',\n",
       " '202312',\n",
       " '202401',\n",
       " '202402',\n",
       " '202403',\n",
       " '202404',\n",
       " '202405',\n",
       " '202406',\n",
       " '202407',\n",
       " '202408',\n",
       " '202409',\n",
       " '202410',\n",
       " '202411',\n",
       " '202412']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fldr = Path(results_fldr)\n",
    "print(test_fldr)\n",
    "\n",
    "test_process = [f.name for f in test_fldr.iterdir() if f.is_dir()]\n",
    "test_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results_df = process_subdir_hdgfiles(results_fldr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HedgeFile_Dt</th>\n",
       "      <th>Attrib_Type</th>\n",
       "      <th>HedgeDate</th>\n",
       "      <th>CompID</th>\n",
       "      <th>Indicator</th>\n",
       "      <th>Bbg_Idx</th>\n",
       "      <th>Fund_Name</th>\n",
       "      <th>Opt_Type</th>\n",
       "      <th>Strike</th>\n",
       "      <th>Cap/Rate</th>\n",
       "      <th>Budget</th>\n",
       "      <th>PolicyCount</th>\n",
       "      <th>Base_Liab_Ntnl</th>\n",
       "      <th>Notional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-03</td>\n",
       "      <td>New</td>\n",
       "      <td>2023-07-03</td>\n",
       "      <td>1</td>\n",
       "      <td>NASIDX</td>\n",
       "      <td>NDX Index</td>\n",
       "      <td>NASDAQ-100 1 Yr Pt-to-Pt 100 Part w Cap</td>\n",
       "      <td>Call Spread</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>20.00</td>\n",
       "      <td>3,287.51</td>\n",
       "      <td>3,188.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-03</td>\n",
       "      <td>New</td>\n",
       "      <td>2023-07-03</td>\n",
       "      <td>1</td>\n",
       "      <td>NASIDX</td>\n",
       "      <td>NDX Index</td>\n",
       "      <td>NASDAQ-100 1 Yr Pt-to-Pt 100 Part w Cap</td>\n",
       "      <td>Call Spread</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5,043.19</td>\n",
       "      <td>4,891.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-03</td>\n",
       "      <td>New</td>\n",
       "      <td>2023-07-03</td>\n",
       "      <td>1</td>\n",
       "      <td>NASIDX</td>\n",
       "      <td>NDX Index</td>\n",
       "      <td>NASDAQ-100 1 Yr Pt-to-Pt 100 Part w Cap</td>\n",
       "      <td>Call Spread</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1,607.00</td>\n",
       "      <td>270,547.46</td>\n",
       "      <td>262,431.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-03</td>\n",
       "      <td>New</td>\n",
       "      <td>2023-07-03</td>\n",
       "      <td>1</td>\n",
       "      <td>INDEX</td>\n",
       "      <td>SPX Index</td>\n",
       "      <td>S&amp;P 500 1 Yr Pt-to-Pt 100 Part w Cap</td>\n",
       "      <td>Call Spread</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>373.00</td>\n",
       "      <td>171,547.68</td>\n",
       "      <td>166,401.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-03</td>\n",
       "      <td>New</td>\n",
       "      <td>2023-07-03</td>\n",
       "      <td>1</td>\n",
       "      <td>INDEX</td>\n",
       "      <td>SPX Index</td>\n",
       "      <td>S&amp;P 500 1 Yr Pt-to-Pt 100 Part w Cap</td>\n",
       "      <td>Call Spread</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>90.00</td>\n",
       "      <td>509,891.40</td>\n",
       "      <td>494,594.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>Changed</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>26</td>\n",
       "      <td>INXFEE</td>\n",
       "      <td>SPX Index</td>\n",
       "      <td>S&amp;P 500 1 Yr Pt-to-Pt Uncapped w Fee</td>\n",
       "      <td>Call</td>\n",
       "      <td>1.09</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.91</td>\n",
       "      <td>6.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>Changed</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>1</td>\n",
       "      <td>INXSPC</td>\n",
       "      <td>SPX Index</td>\n",
       "      <td>S&amp;P 500 1 Yr Specified Rate</td>\n",
       "      <td>Digital</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>5.00</td>\n",
       "      <td>464.70</td>\n",
       "      <td>441.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>Changed</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>1</td>\n",
       "      <td>INXSPC</td>\n",
       "      <td>SPX Index</td>\n",
       "      <td>S&amp;P 500 1 Yr Specified Rate</td>\n",
       "      <td>Digital</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>25.00</td>\n",
       "      <td>8,682.88</td>\n",
       "      <td>8,248.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>Changed</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>26</td>\n",
       "      <td>INXSPC</td>\n",
       "      <td>SPX Index</td>\n",
       "      <td>S&amp;P 500 1 Yr Specified Rate</td>\n",
       "      <td>Digital</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>8.00</td>\n",
       "      <td>497.07</td>\n",
       "      <td>377.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>Changed</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>1</td>\n",
       "      <td>MARPRT</td>\n",
       "      <td>SPMARC5P Index</td>\n",
       "      <td>S&amp;P MARC 5% 1 Yr Pt-to-Pt Uncapped</td>\n",
       "      <td>Call</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>171.00</td>\n",
       "      <td>72,038.70</td>\n",
       "      <td>163,985.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1788 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HedgeFile_Dt Attrib_Type   HedgeDate  CompID Indicator         Bbg_Idx  \\\n",
       "0      2023-07-03         New  2023-07-03       1    NASIDX       NDX Index   \n",
       "1      2023-07-03         New  2023-07-03       1    NASIDX       NDX Index   \n",
       "2      2023-07-03         New  2023-07-03       1    NASIDX       NDX Index   \n",
       "3      2023-07-03         New  2023-07-03       1     INDEX       SPX Index   \n",
       "4      2023-07-03         New  2023-07-03       1     INDEX       SPX Index   \n",
       "...           ...         ...         ...     ...       ...             ...   \n",
       "1783   2024-12-02     Changed  2024-12-02      26    INXFEE       SPX Index   \n",
       "1784   2024-12-02     Changed  2024-12-02       1    INXSPC       SPX Index   \n",
       "1785   2024-12-02     Changed  2024-12-02       1    INXSPC       SPX Index   \n",
       "1786   2024-12-02     Changed  2024-12-02      26    INXSPC       SPX Index   \n",
       "1787   2024-12-02     Changed  2024-12-02       1    MARPRT  SPMARC5P Index   \n",
       "\n",
       "                                    Fund_Name     Opt_Type  Strike  Cap/Rate  \\\n",
       "0     NASDAQ-100 1 Yr Pt-to-Pt 100 Part w Cap  Call Spread    1.00      0.10   \n",
       "1     NASDAQ-100 1 Yr Pt-to-Pt 100 Part w Cap  Call Spread    1.00      0.10   \n",
       "2     NASDAQ-100 1 Yr Pt-to-Pt 100 Part w Cap  Call Spread    1.00      0.10   \n",
       "3        S&P 500 1 Yr Pt-to-Pt 100 Part w Cap  Call Spread    1.00      0.07   \n",
       "4        S&P 500 1 Yr Pt-to-Pt 100 Part w Cap  Call Spread    1.00      0.10   \n",
       "...                                       ...          ...     ...       ...   \n",
       "1783     S&P 500 1 Yr Pt-to-Pt Uncapped w Fee         Call    1.09     10.00   \n",
       "1784              S&P 500 1 Yr Specified Rate      Digital    1.00      0.06   \n",
       "1785              S&P 500 1 Yr Specified Rate      Digital    1.00      0.07   \n",
       "1786              S&P 500 1 Yr Specified Rate      Digital    1.00      0.07   \n",
       "1787       S&P MARC 5% 1 Yr Pt-to-Pt Uncapped         Call    1.00     10.00   \n",
       "\n",
       "      Budget  PolicyCount  Base_Liab_Ntnl   Notional  \n",
       "0       0.05        20.00        3,287.51   3,188.88  \n",
       "1       0.05         7.00        5,043.19   4,891.89  \n",
       "2       0.06     1,607.00      270,547.46 262,431.04  \n",
       "3       0.04       373.00      171,547.68 166,401.25  \n",
       "4       0.05        90.00      509,891.40 494,594.66  \n",
       "...      ...          ...             ...        ...  \n",
       "1783    0.03         0.00            7.91       6.01  \n",
       "1784    0.04         5.00          464.70     441.47  \n",
       "1785    0.05        25.00        8,682.88   8,248.74  \n",
       "1786    0.05         8.00          497.07     377.77  \n",
       "1787    0.02       171.00       72,038.70 163,985.45  \n",
       "\n",
       "[1788 rows x 14 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results_df.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['202307', '202308', '202309', '202310', '202311', '202312', '202401', '202402', '202403', '202404', '202405', '202406', '202407', '202408', '202409', '202410', '202411', '202412']\n"
     ]
    }
   ],
   "source": [
    "# test_sub_dirs = [x[1] for x  in os.walk(results_fldr)]\n",
    "test_sub_dirs = [x[1] for x in os.walk(results_fldr)]\n",
    "test_sub_dirs = test_sub_dirs[0]\n",
    "\n",
    "print(test_sub_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub_dir = '202405'\n",
    "test_dir = os.path.join(results_fldr, test_sub_dir)\n",
    "\n",
    "orig_file = 'iul_liab_summary.csv'\n",
    "true_file = 'iul_liab_summary_TRUE_UP.csv'\n",
    "\n",
    "orig_path = os.path.join(test_dir, orig_file)\n",
    "true_path = os.path.join(test_dir, true_file)\n",
    "\n",
    "final_cols = ['HedgeFile_Dt', 'Attrib_Type', 'HedgeDate', 'CompID', 'Indicator', 'Bbg_Idx', 'Fund_Name', 'Opt_Type', 'Strike', 'Cap/Rate', 'Budget', 'PolicyCount', 'Base_Liab_Ntnl', 'Notional']\n",
    "df_cols = ['HedgeDate',\t'CompID', 'Indicator', 'Bbg_Idx', 'Fund_Name', 'Opt_Type', 'Strike', 'Cap/Rate', 'Budget', 'PolicyCount', 'Base_Liab_Ntnl', 'Notional']\n",
    "\n",
    "orig_df = pd.read_csv(orig_path)\n",
    "orig_df = orig_df[df_cols]\n",
    "\n",
    "true_df = pd.read_csv(true_path)\n",
    "true_df = true_df[df_cols]\n",
    "\n",
    "orig_df['HedgeDate'] = pd.to_datetime(orig_df['HedgeDate']).dt.date\n",
    "true_df['HedgeDate'] = pd.to_datetime(true_df['HedgeDate']).dt.date\n",
    "hedge_dt = orig_df['HedgeDate'].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S0053071\\AppData\\Local\\Temp\\ipykernel_32400\\3241378652.py:4: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  test_df = pd.read_csv(test_file, index_col=False, header=None, names=hedgefile_colnames, skipfooter=2, engine='python')\n"
     ]
    }
   ],
   "source": [
    "test_file = r'G:\\MarketRiskMgmt\\Pricing Requests\\2024-Orion - IUL Hedging\\RGA_Process\\2_Results\\202412\\Review Automated VBA\\12_2024_HEDGE_ORIG.txt'\n",
    "hedgefile_colnames = ['CompID', 'PolicyNum', 'Plan', 'IssueDate', 'Indicator', 'Tranx', 'Rev', 'Dept_Desk', 'Entry_Date', 'AsOf_Date', 'Base_Liab_Ntnl', 'Part', 'Cap', 'MGIR_(Cap)', 'Floor', 'Spec_Rate', 'Spread', 'Asset_Charge', 'Multiplier']\n",
    "\n",
    "test_df = pd.read_csv(test_file, index_col=False, header=None, names=hedgefile_colnames, skipfooter=2, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(142757763.13)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Base_Liab_Ntnl'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
